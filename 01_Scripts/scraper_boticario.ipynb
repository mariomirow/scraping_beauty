{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, datetime\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapeando a árvore de URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_links(links, link_blacklist, base_url):\n",
    "\n",
    "    passlist = [l for l in links if not any(xl in l for xl in link_blacklist)] # Filtra links que contem texto constante na blacklist    \n",
    "    filtered_list = []\n",
    "    discarded_list = []\n",
    "    \n",
    "    for i in passlist:\n",
    "        if (len(i) <= 1) or i == base_url: # Descarta se for so uma barra ou o url base do boticario\n",
    "            discarded_list.append(i)\n",
    "        elif i[:len(base_url)] == base_url: # Mantem se for um url do boticario\n",
    "            filtered_list.append(i)\n",
    "        elif i[:4] == 'http':\n",
    "            discarded_list.append(i)\n",
    "        elif i[0] == '/': # Monta o url completo\n",
    "            filtered_list.append(base_url+i)\n",
    "        elif i[0] != '/': # Monta o url completo\n",
    "            filtered_list.append(base_url+'/'+i)\n",
    "        else:\n",
    "            discarded_list.append(i)\n",
    "\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_links(session, seed_url, base_url, link_blacklist):\n",
    "    r = session.get(seed_url)\n",
    "\n",
    "    return filter_links(r.html.links, link_blacklist, base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_type(session, link):\n",
    "    r = session.get(link)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    page_type = 'Unknown'\n",
    "\n",
    "    try:\n",
    "        script = soup.find_all(\"script\")[1]\n",
    "        pattern = re.compile(\"blz.pageType = (.*?);\") # Acha essa variavel entre os elementos com tag script\n",
    "        page_type = pattern.findall(script.string)[0].replace(\"'\",\"\") # Remove aspas simples do texto\n",
    "\n",
    "    except Exception as e:\n",
    "        if debug_mode: print(e)\n",
    "    \n",
    "    return page_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_link(link, product_set, discard_set): # Verifica se o link ja foi visto ou nao\n",
    "    new = not(link in product_set or link in discard_set)\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_mapper(session, base_url, seed_links, link_type_blacklist, link_blacklist, product_max):\n",
    "    product_set = set() # Pilha de produtos\n",
    "    discard_set = set() # Pilha de descarte\n",
    "    seed_set = set(seed_links) # Pilha de links\n",
    " \n",
    "    while (len(seed_set) > 0) and (len(product_set) < product_max):\n",
    "        link = seed_set.pop() # Pega o primeiro link da lista\n",
    "        new = new_link(link, product_set, discard_set)\n",
    "        \n",
    "        if debug_mode:\n",
    "            print(\"---------------------------------------\")\n",
    "            print(\"Product stack: \", len(product_set))\n",
    "            print(\"Discard stack: \", len(discard_set))\n",
    "            print(\"Link stack: \", len(seed_set))\n",
    "            print(\"Current link: \", link)\n",
    "            print(\"New link: \", new)\n",
    "\n",
    "        if new: # Continua so se for um link novo\n",
    "            lk_type = link_type(session, link) # E pega seu tipo\n",
    "\n",
    "            if debug_mode:\n",
    "                print(\"Link type: \", lk_type)\n",
    "\n",
    "            if lk_type not in link_type_blacklist: # Continua so se nao for um dos tipos no blacklist,\n",
    "\n",
    "                if lk_type == \"Produto\": # Se for um produto\n",
    "                    product_set.add(link) # Coloca na pilha de produtos\n",
    "                    \n",
    "                    if debug_mode:\n",
    "                        print(\"Link added to product stack\")\n",
    "\n",
    "                else: # Se nao for um produto (pode ser Categoria, SubCategoria, Landing, Linha, Marca, etc.)\n",
    "                    potential_links = get_filtered_links(session, link, base_url, link_blacklist) # Lista os links dentro dele\n",
    "                    \n",
    "                    new_links = [l for l in potential_links if new_link(l, product_set, discard_set)] # Destes, pega apenas os novos\n",
    "                    \n",
    "                    old_size = len(seed_set)\n",
    "                    for nl in new_links:            \n",
    "                        seed_set.add(nl) # Adiciona links novos aa lista principal\n",
    "                    new_size = len(seed_set)\n",
    "\n",
    "                    if debug_mode:\n",
    "                        print(new_size-old_size, \" new links added to link stack\")\n",
    "\n",
    "        discard_set.add(link) # Adiciona link que acabamos de ver aa pilha de descarte\n",
    "\n",
    "    return product_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegando dados de um único produto\n",
    "\n",
    "Dados desejados:\n",
    "- País\n",
    "- Concorrente\n",
    "- Data scrape\n",
    "- ID produto\n",
    "- Título\n",
    "- Descrição\n",
    "- Preço atual\n",
    "- Preço antigo\n",
    "- Desconto atual\n",
    "- Moeda\n",
    "- Disponibilidade\n",
    "- Condição\n",
    "- Departamento\n",
    "- Categoria\n",
    "- Marca\n",
    "- Linha\n",
    "- URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_data(session, link): # A partir da pagina do item, busca todas suas informacoes pertinentes\n",
    "    r = session.get(link)\n",
    "    \n",
    "    item = BeautifulSoup(r.text, \"html.parser\").head # Maior parte dos dados esta na seção 'head', sobe o 'parent' se precisar de algo de fora\n",
    "    \n",
    "    pais = \"Brasil\"\n",
    "    competidor = \"O Boticario\"\n",
    "    data = date.today().strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    # Description\n",
    "    try:\n",
    "        description = item.find(\"meta\", {\"property\":\"og:description\"}).attrs[\"content\"]\n",
    "    except Exception as e:\n",
    "        description = None\n",
    "        if debug_mode:print(e)\n",
    "    \n",
    "    # Availability\n",
    "    try:\n",
    "        availability = item.find(\"meta\", {\"property\":\"product:availability\"}).attrs[\"content\"]\n",
    "    except Exception as e:\n",
    "        availability = None\n",
    "        if debug_mode:print(e)\n",
    "\n",
    "    # Condition\n",
    "    try:\n",
    "        condition = item.find(\"meta\", {\"property\":\"product:condition\"}).attrs[\"content\"]\n",
    "    except Exception as e:\n",
    "        condition = None\n",
    "        if debug_mode:print(e)\n",
    "\n",
    "    # Price\n",
    "    try:\n",
    "        price = item.find(\"meta\", {\"property\":\"product:price:amount\"}).attrs[\"content\"]\n",
    "        price = float(price)\n",
    "    except Exception as e:\n",
    "        price = None\n",
    "        if debug_mode:print(e)\n",
    "\n",
    "    # Currency\n",
    "    try:\n",
    "        currency = item.find(\"meta\", {\"property\":\"product:price:currency\"}).attrs[\"content\"]\n",
    "    except Exception as e:\n",
    "        currency = None\n",
    "        if debug_mode:print(e)\n",
    "    \n",
    "    # ID\n",
    "    try:\n",
    "        id = item.find(\"meta\", {\"property\":\"product:retailer_item_id\"}).attrs[\"content\"]\n",
    "    except Exception as e:\n",
    "        id = None\n",
    "        if debug_mode:print(e)\n",
    "\n",
    "    # Title\n",
    "    try:\n",
    "        title = item.find(\"meta\", {\"property\":\"og:title\"}).attrs[\"content\"].split(\"|\")[0].strip()\n",
    "    except Exception as e:\n",
    "        title = None\n",
    "        if debug_mode:print(e)\n",
    "        \n",
    "    # URL\n",
    "    try:\n",
    "        url = item.find(\"meta\", {\"property\":\"og:url\"}).attrs[\"content\"]\n",
    "    except Exception as e:\n",
    "        url = None\n",
    "        if debug_mode:print(e)\n",
    "        \n",
    "    # MaxPrice\n",
    "    try:\n",
    "        maxprice = item.parent.find(\"strong\", {\"class\": \"nproduct-price-max\"}).s.text.strip().strip(\"R$\").strip().replace(',','.')\n",
    "        maxprice = float(maxprice)\n",
    "    except Exception as e:\n",
    "        maxprice = None\n",
    "        if debug_mode:print(e)\n",
    "\n",
    "    # Outros atributos\n",
    "    pattern = re.compile(\"blz.globals.pageTree = (.*?);\") # Acha essa variavel entre os elementos com tag script\n",
    "\n",
    "    scripts = item.parent.find_all('script')[1] # Variável fica no segundo bloco 'script', serve para tracking do Google Tag Manager\n",
    "\n",
    "    patt = pattern.findall(scripts.string)[0]\n",
    "    attr = json.loads(patt) # Transforma em JSON para facilitar a conversao\n",
    "\n",
    "    # Departamento\n",
    "    try:\n",
    "        departamento = attr['department']\n",
    "    except Exception as e:\n",
    "        departamento = None\n",
    "        if debug_mode:print(e)\n",
    "        \n",
    "    # Categoria\n",
    "    try:\n",
    "        categoria = attr['category']\n",
    "    except Exception as e:\n",
    "        categoria = None\n",
    "        if debug_mode:print(e)\n",
    "\n",
    "    # Marca\n",
    "    try:\n",
    "        marca = attr['brand']\n",
    "    except Exception as e:\n",
    "        marca = None\n",
    "        if debug_mode:print(e)\n",
    "        \n",
    "    # Linha\n",
    "    try:\n",
    "        linha = attr['brandLine']\n",
    "    except Exception as e:\n",
    "        linha = None\n",
    "        if debug_mode:print(e)\n",
    "        \n",
    "    # Demais atributos\n",
    "    try:\n",
    "        atributos = attr['attributes'] # Esses aqui são um dict dentro do JSON, crio um novo dict simplificado a partir deste\n",
    "        tempDict = {}\n",
    "        for i in atributos:\n",
    "            k = i['name']\n",
    "\n",
    "            v = []\n",
    "            for j in i['values']:\n",
    "                v.append(j['name'])\n",
    "\n",
    "            tempDict[k] = \",\".join(v)\n",
    "    except Exception as e:\n",
    "        tempDict = {}\n",
    "        if debug_mode:print(e)\n",
    "            \n",
    "    d = {\t\n",
    "            \"País\":pais,\n",
    "            \"Concorrente\":competidor,\n",
    "            \"Data scrape\":data,\n",
    "            \"ID produto\":id,\n",
    "            \"Título\":title,\n",
    "            \"Descrição\":description,\n",
    "            \"Preço atual\":price,\n",
    "            \"Preço antigo\":maxprice,\n",
    "            \"Moeda\":currency,\n",
    "            \"Disponibilidade\":availability,\n",
    "            \"Condição\":condition,\n",
    "            \"Departamento\":departamento,\n",
    "            \"Categoria\":categoria,\n",
    "            \"Marca\":marca,\n",
    "            \"Linha\":linha,\n",
    "            \"URL\":url\n",
    "        }\n",
    "\n",
    "    d.update(tempDict) # Inclui demais atributos\n",
    "\n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_items(session, links):\n",
    "    df = pd.DataFrame()\n",
    "    for link in links:\n",
    "        try:\n",
    "            item_data = get_item_data(session, link)\n",
    "            df = df.append(item_data, ignore_index=True)\n",
    "        except Exception as e:\n",
    "            if debug_mode: print(e)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(product_max = 10_000_000):\n",
    "    \n",
    "    session = HTMLSession()\n",
    "    base_url = \"https://www.boticario.com.br\"\n",
    "    seed_url = \"https://www.boticario.com.br/institucional/mapasite/\"\n",
    "\n",
    "    link_blacklist = ['atendimento','autenticacao','compre-pelo-whatsapp','institucional','minha-conta','nossa-historia','sacola','dicas-de-beleza','clube','?']\n",
    "    link_type_blacklist = ['Institucional', 'Unknown', 'quiz-giftable']\n",
    "\n",
    "    # Scraping\n",
    "    seed_links = get_filtered_links(session, seed_url, base_url, link_blacklist)\n",
    "\n",
    "    products = product_mapper(session, base_url, seed_links, link_type_blacklist, link_blacklist, product_max)\n",
    "\n",
    "#    df2 = pd.read_excel(\"../2023_05_18_boticario.xlsx\")\n",
    "#    products = df2['URL'].to_list()\n",
    "    \n",
    "    df = get_all_items(session, products)\n",
    "    \n",
    "    # Reordenando\n",
    "    first = ['País', 'Concorrente', 'Data scrape', 'ID produto', 'Título', 'Descrição', 'Preço atual', 'Preço antigo', 'Moeda', 'Disponibilidade', 'Condição', 'Departamento', 'Categoria', 'Marca', 'Linha', 'URL']\n",
    "    cols = first + sorted([c for c in df.columns.to_list() if c not in first])   \n",
    "\n",
    "    try:\n",
    "        df = df[cols]\n",
    "    except Exception as e:\n",
    "        if debug_mode: print(e)\n",
    "    \n",
    "    df.to_excel(\"../02_Results/\"+date.today().strftime(\"%Y_%m_%d\")+\"_\"+\"boticario.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    start = datetime.now()\n",
    "    main()\n",
    "    end = datetime.now()\n",
    "\n",
    "    print(\"Time elapsed: \", end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
